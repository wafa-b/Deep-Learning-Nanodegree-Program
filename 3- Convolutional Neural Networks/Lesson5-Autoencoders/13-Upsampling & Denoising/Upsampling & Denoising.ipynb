{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolutional Autoencoder\n",
    "\n",
    "Sticking with the MNIST dataset, let's improve our autoencoder's performance using convolutional layers. We'll build a convolutional autoencoder to compress the MNIST dataset. \n",
    "\n",
    ">The encoder portion will be made of convolutional and pooling layers and the decoder will be made of **upsampling and convolutional layers**.\n",
    "\n",
    "##### Compressed Representation\n",
    "\n",
    "A compressed representation can be great for saving and sharing any kind of data in a way that is more efficient than storing raw data. In practice, the compressed representation often holds key information about an input image and we can use it for denoising images or oher kinds of reconstruction and transformation!\n",
    "\n",
    "Let's get started by importing our libraries and getting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#Convert data to torch.FloatTensor\n",
    "transform=transforms.ToTensor()\n",
    "\n",
    "#Load the training and test datasets\n",
    "train_data=datasets.MNIST(root='data',train=True,download=True,transform=transform)\n",
    "test_data=datasets.MNIST(root='data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test dataloaders\n",
    "num_workers=0\n",
    "#How many samples per batch to load\n",
    "batch_size=20\n",
    "\n",
    "#Prepare data loaders\n",
    "train_loader=torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader=torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a57e950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "#Obtain one batch of training images\n",
    "dataiter=iter(train_loader)\n",
    "images,labels=dataiter.next()\n",
    "images=images.numpy()\n",
    "\n",
    "#Get one image from the batch\n",
    "img=np.squeeze(images[0])\n",
    "\n",
    "fig=plt.figure(figsize=(5,5)) \n",
    "ax=fig.add_subplot(111)\n",
    "ax.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolutional  Autoencoder\n",
    "\n",
    "The encoder part of the network will be a typical convolutional pyramid. Each convolutional layer will be followed by a max-pooling layer to reduce the dimensions of the layers. The decoder though might be something new to you. The decoder needs to convert from a narrow representation to a wide reconstructed image. For example, the representation could be a 4x4x8 max-pool layer. This is the output of the encoder, but also the input to the decoder. We want to get a 28x28x1 image out from the decoder so we need to work our way back up from the narrow decoder input layer. A schematic of the network is shown below.\n",
    "\n",
    "##### Upsampling + Convolutions, Decoder\n",
    "\n",
    "This decoder uses a combination of nearest-neighbor **upsampling and normal convolutional layers** to increase the width and height of the input layers.\n",
    "\n",
    "It is important to note that transpose convolution layers can lead to artifacts in the final images, such as checkerboard patterns. This is due to overlap in the kernels which can be avoided by setting the stride and kernel size equal. In [this Distill article](http://distill.pub/2016/deconv-checkerboard/) from Augustus Odena, *et al*, the authors show that these checkerboard artifacts can be avoided by resizing the layers using nearest neighbor or bilinear interpolation (upsampling) followed by a convolutional layer. This is the approach we take, here.\n",
    "\n",
    "##### TODO: Build the network shown above. \n",
    "> Build the encoder out of a series of convolutional and pooling layers. \n",
    "> When building the decoder, use a combination of upsampling and normal, convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoencoder(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Define the NN architecture\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        ##Encoder layers ##\n",
    "        #conv layer (depth from 1 --> 16), 3x3 kernels\n",
    "        self.conv1=nn.Conv2d(1,16,3,padding=1)  \n",
    "        #conv layer (depth from 16 --> 8), 3x3 kernels\n",
    "        self.conv2=nn.Conv2d(16,4,3,padding=1)\n",
    "        #pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        \n",
    "        ##Decoder layers ##\n",
    "        self.conv4=nn.Conv2d(4,16,3,padding=1)\n",
    "        self.conv5=nn.Conv2d(16,1,3,padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Add layer, with relu activation function\n",
    "        #and maxpooling after\n",
    "        x=F.relu(self.conv1(x))\n",
    "        x=self.pool(x)\n",
    "        #Add hidden layer, with relu activation function\n",
    "        x=F.relu(self.conv2(x))\n",
    "        x=self.pool(x)  # compressed representation\n",
    "        \n",
    "        ##Decoder \n",
    "        #Upsample,followed by a conv layer, with relu activation function  \n",
    "        #This function is called `interpolate` in some PyTorch versions\n",
    "        x=F.upsample(x,scale_factor=2,mode='nearest')\n",
    "        x=F.relu(self.conv4(x))\n",
    "        #Upsample again, output should have a sigmoid applied\n",
    "        x=F.upsample(x,scale_factor=2,mode='nearest')\n",
    "        x=F.sigmoid(self.conv5(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "#Initialize the NN\n",
    "model=ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training\n",
    "\n",
    "Here I'll write a bit of code to train the network. I'm not too interested in validation here, so I'll just monitor the training loss and the test loss afterwards. \n",
    "\n",
    "We are not concerned with labels in this case, just images, which we can get from the `train_loader`. Because we're comparing pixel values in input and output images, it will be best to use a loss that is meant for a regression task. Regression is all about comparing quantities rather than probabilistic values. So, in this case, I'll use `MSELoss`. And compare output images and input images as follows:\n",
    "```\n",
    "loss = criterion(outputs, images)\n",
    "```\n",
    "\n",
    "Otherwise, this is pretty straightfoward training with PyTorch. We flatten our images, pass them into the autoencoder, and record the training loss as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify loss function\n",
    "criterion=nn.MSELoss()\n",
    "\n",
    "#Specify loss function\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wafa/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/Users/wafa/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.255265\n",
      "Epoch: 2 \tTraining Loss: 2.240053\n",
      "Epoch: 3 \tTraining Loss: 2.240052\n",
      "Epoch: 4 \tTraining Loss: 2.240052\n",
      "Epoch: 5 \tTraining Loss: 2.240052\n",
      "Epoch: 6 \tTraining Loss: 2.240052\n",
      "Epoch: 7 \tTraining Loss: 2.240052\n",
      "Epoch: 8 \tTraining Loss: 2.240052\n",
      "Epoch: 9 \tTraining Loss: 2.240052\n",
      "Epoch: 10 \tTraining Loss: 2.240052\n",
      "Epoch: 11 \tTraining Loss: 2.240052\n",
      "Epoch: 12 \tTraining Loss: 2.240052\n",
      "Epoch: 13 \tTraining Loss: 2.240052\n",
      "Epoch: 14 \tTraining Loss: 2.240052\n",
      "Epoch: 15 \tTraining Loss: 2.240052\n",
      "Epoch: 16 \tTraining Loss: 2.240052\n",
      "Epoch: 17 \tTraining Loss: 2.240052\n",
      "Epoch: 18 \tTraining Loss: 2.240052\n",
      "Epoch: 19 \tTraining Loss: 2.240052\n",
      "Epoch: 20 \tTraining Loss: 2.240052\n",
      "Epoch: 21 \tTraining Loss: 2.240052\n",
      "Epoch: 22 \tTraining Loss: 2.240052\n",
      "Epoch: 23 \tTraining Loss: 2.240052\n",
      "Epoch: 24 \tTraining Loss: 2.240052\n",
      "Epoch: 25 \tTraining Loss: 2.240052\n",
      "Epoch: 26 \tTraining Loss: 2.240052\n",
      "Epoch: 27 \tTraining Loss: 2.240052\n",
      "Epoch: 28 \tTraining Loss: 2.240052\n",
      "Epoch: 29 \tTraining Loss: 2.240052\n",
      "Epoch: 30 \tTraining Loss: 2.240052\n"
     ]
    }
   ],
   "source": [
    "#Number of epochs to train the model\n",
    "n_epochs=30\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    #Monitor training loss\n",
    "    train_loss=0.0\n",
    "    \n",
    "    #Train the model\n",
    "    for data in train_loader:\n",
    "        #_ stands in for labels, here\n",
    "        #no need to flatten images\n",
    "        images,_=data\n",
    "        #Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs=model(images)\n",
    "        #Calculate the loss\n",
    "        loss=criterion(outputs,images)\n",
    "        #Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        #Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        #Update running training loss\n",
    "        train_loss+=loss.item()*images.size(0)\n",
    "            \n",
    "    #Print avg training statistics \n",
    "    train_loss=train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking out the results\n",
    "\n",
    "Below I've plotted some of the test images along with their reconstructions. For the most part these look pretty good except for some blurriness in some parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtain one batch of test images\n",
    "dataiter=iter(test_loader)\n",
    "images,labels=dataiter.next()\n",
    "\n",
    "#Get sample outputs\n",
    "output=model(images)\n",
    "#Prep images for display\n",
    "images=images.numpy()\n",
    "\n",
    "#Output is resized into a batch of iages\n",
    "output=output.view(batch_size,1,28,28)\n",
    "#Use detach when it's an output that requires_grad\n",
    "output=output.detach().numpy()\n",
    "\n",
    "#Plot the first ten input images and then reconstructed images\n",
    "fig,axes= plt.subplots(nrows=2,ncols=10,sharex=True,sharey=True,figsize=(25,4))\n",
    "\n",
    "#Input images on top row, reconstructions on bottom\n",
    "for images,row in zip([images,output],axes):\n",
    "    for img, ax in zip(images,row):\n",
    "        ax.imshow(np.squeeze(img),cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
