{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "#Define transform top normalize data\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                             transforms.Normalize((0.5,),(0.5,)),\n",
    "                             ])\n",
    "#Downloade Training data\n",
    "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
    "#Load training data\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2979, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Build feed-forward network\n",
    "model=nn.Sequential(nn.Linear(784,128),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(128,64),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(64,10))\n",
    "#Define loss\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "#Get data\n",
    "images,labels=next(iter(trainloader))\n",
    "#Flatten images\n",
    "images=images.view(images.shape[0],-1)\n",
    "#Forward pass\n",
    "logits=model(images)\n",
    "#Calculate loss with logits & labels\n",
    "loss=criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3209, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Solutin\n",
    "#Build feed-forward network\n",
    "model=nn.Sequential(nn.Linear(784,128),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(128,64),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(64,10),\n",
    "                   nn.LogSoftmax(dim=1))\n",
    "#Define loss\n",
    "criterion=nn.NLLLoss()\n",
    "#Get data\n",
    "images,labels=next(iter(trainloader))\n",
    "#Flatten images\n",
    "images=images.view(images.shape[0],-1)\n",
    "#Forward pass\n",
    "logps=model(images)\n",
    "#Calculte logps & labels\n",
    "loss=criterion(logps,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1886, -1.6551],\n",
      "        [ 0.6446, -2.6689]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0356, 2.7394],\n",
      "        [0.4155, 7.1230]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x120482d10>\n"
     ]
    }
   ],
   "source": [
    "#shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5784, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0943, -0.8276],\n",
      "        [ 0.3223, -1.3344]])\n",
      "tensor([[ 0.0943, -0.8276],\n",
      "        [ 0.3223, -1.3344]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(nn.Linear(784,128),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(128,64),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(64,10),\n",
    "                   nn.LogSoftmax(dim=1))\n",
    "criterion=nn.NLLLoss()\n",
    "images,labels=next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "logps=model(images)\n",
    "loss=criterion(logps,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Background pass: \n",
      " None\n",
      "Afer Background pass: \n",
      " tensor([[-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [ 0.0017,  0.0017,  0.0017,  ...,  0.0017,  0.0017,  0.0017],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n"
     ]
    }
   ],
   "source": [
    "print('Before Background pass: \\n',model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('Afer Background pass: \\n',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0124, -0.0115, -0.0264,  ...,  0.0204,  0.0273, -0.0343],\n",
      "        [ 0.0097,  0.0126, -0.0218,  ..., -0.0023,  0.0341, -0.0125],\n",
      "        [ 0.0227,  0.0177, -0.0086,  ...,  0.0219,  0.0022, -0.0006],\n",
      "        ...,\n",
      "        [-0.0189, -0.0268,  0.0257,  ...,  0.0314, -0.0098, -0.0316],\n",
      "        [-0.0266,  0.0098,  0.0020,  ...,  0.0066,  0.0218, -0.0272],\n",
      "        [-0.0048, -0.0341,  0.0226,  ..., -0.0274, -0.0183,  0.0240]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "        [-0.0031, -0.0031, -0.0031,  ..., -0.0031, -0.0031, -0.0031],\n",
      "        ...,\n",
      "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "# Clear the gradients\n",
    "optimizer.zero_grad()\n",
    "#Forward pass\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "#Backward pass\n",
    "loss.backward()\n",
    "#update weights\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training for real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8736616794996932\n",
      "Training loss: 0.7996409829300858\n",
      "Training loss: 0.5022600839641302\n",
      "Training loss: 0.41437175220200245\n",
      "Training loss: 0.3730670227361386\n"
     ]
    }
   ],
   "source": [
    "#Solution\n",
    "#Build feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "#Define loss\n",
    "criterion = nn.NLLLoss()\n",
    "#Optimizers to update the weights with the gradients\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    #Get data\n",
    "    for images, labels in trainloader:\n",
    "        #Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        #Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "images, labels = next(iter(trainloader))\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
